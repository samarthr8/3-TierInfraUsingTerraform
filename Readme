Project: Created infrastructure for a 3 tier application along with compute, storage, containerisation tools, databases using Terraform for various 
         prod and non-prod environments using workspaces. 

To do this project, I followed these steps:

1. I created the basic 3 tier architecture using modules in Terraform. Modules are reusable components that can be used to create and manage   
   resources. I used variables to make my code more flexible and configurable for different environments.

2. I saved the .tfstate file (backend file) to a remote location (S3) protected with DynamoDB locking mechanism. The .tfstate file stores the state 
   of the infrastructure that Terraform manages. S3 is a cloud storage service that can store the state file securely and reliably. DynamoDB is a  
   key-value database that can provide locking to prevent concurrent modifications of the state file by multiple users or processes.

3. I created .tfvars files for every different environment. .tfvars files are files that contain values for variables that can be passed to 
   Terraform commands. They allow me to customize the configuration for each environment without changing the main code.

4. I created var.tf to mention all the variables. var.tf is a file that defines the variables that are used in the configuration. It specifies the 
   name, type, description, and default value of each variable.

5. Then I used workspaces concept to create different workspaces for each environment . Workspaces are separate instances of state data inside the 
   same Terraform working directory
		1. They allow me to manage multiple sets of non-overlapping resources with the same configuration
		2. For example, I can have a workspace for development, testing, and production environments.

6. Then I used terraform apply -var-file="env.tfvars" command to apply the configuration to the selected workspace. This command reads the values 
   from the .tfvars file and passes them to the variables in the configuration. It then creates or updates the resources in the corresponding 
   environment according to the state file.


Step by Step Process
1. launch  an ec2 machine with follwing specifications - 
	- ubuntu
	- t2.medium
	- 15gb storage
	- 22 port open for my ip in SG
	

2. Install Terraform and awscli on the ec2 machine. 
	Terraform - 
		1. sudo apt update && apt upgrade -y 
		2. sudo apt install -y gnupg software-properties-common curl
		3. curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add -	
		4. sudo apt-add-repository "deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main"
		5. sudo apt update 
		6. sudo apt install terraform
	AWSLCI - 
		1. sudo apt-get install awscli -y


3. create a IAM role (ADMINISTRATOR ACCESS) and attach it to the ec2



4. Clone the repository to the instance -
    git clone https://github.com/samarthr8/3-tier-Infra-Using-Terraform.git


5. Run the following commands -  
        terraform init -: to download the terraform plugin
        terraform plan -: to find the differnece btw current state and desired state
		terraform apply -: to try to achive desired state



6. To secure and share the backend tfstate file need to have a remote backup. S3 will be the best place to share. safe and secure.


7. So before step 4 do this  
        create an S3 bucket - 
		name - tbd-c39-terraform
		region - us east 1
        Update the provider.tf file with the S3 backend code. (saved in terraform folder)
        run terraform init > terraform apply


8. create a dynamodb table, insert LockID as pratition key and update the provider.tf and run the following commands
	    > sudo rm -r .terraform 
	    > terraform init
	    > terraform apply	



9. So this is how you can create the basic 3 tier networking with remote backup of backend(statefile on s3) and protected with lock mechanism
    using dynamo db. As well as create an IAM role and attching it with the ec2 instance.
